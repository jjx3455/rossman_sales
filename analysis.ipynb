{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis of the model\n",
    "   "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models import define_pipelines\n",
    "from models import single_run\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TRAINING_DATA = 'data/train.csv'\n",
    "HOLDOUT_DATA = 'data/holdout.csv'\n",
    "STORE_DATA = 'data/store.csv'\n",
    "TEST_DATA = '' # input the path of the test data file here\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "CORES = -1\n",
    "\n",
    "try:\n",
    "    df_test = pd.read_csv(TEST_DATA)\n",
    "except FileNotFoundError:\n",
    "    print('Test data file not found, using holdout as validation set')\n",
    "    df_test = pd.read_csv(HOLDOUT_DATA)\n",
    "    df_train = pd.read_csv(TRAINING_DATA)\n",
    "else:\n",
    "    print('Test data loaded, using full training data for model training')\n",
    "    df_train = pd.concat([\n",
    "        pd.read_csv(TRAINING_DATA),\n",
    "        pd.read_csv(HOLDOUT_DATA)\n",
    "    ])\n",
    "finally:\n",
    "    df_store = pd.read_csv(STORE_DATA)\n",
    "\n",
    "X_train = df_train.drop(columns='Sales')\n",
    "y_train = df_train.loc[:, 'Sales']\n",
    "X_val = df_test.drop(columns='Sales')\n",
    "y_val = df_test.loc[:, 'Sales']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from data_cleaning import DataCleaning\n",
    "\n",
    "cleaning_settings = dict(\n",
    "    hot_encoded_columns=[\n",
    "        'StateHoliday',\n",
    "        'Assortment',\n",
    "        'SchoolHoliday',\n",
    "    ],\n",
    "    dropped_columns=[\n",
    "        'Store',\n",
    "        'CompetitionOpenSinceMonth',\n",
    "        'CompetitionOpenSinceYear',\n",
    "        'Promo2SinceWeek',\n",
    "        'Promo2SinceYear',\n",
    "        'PromoInterval',\n",
    "        'Date',\n",
    "        'Open',\n",
    "        'StoreType',\n",
    "    ],\n",
    "    filled_in_median=[\n",
    "        'CompetitionDistance',\n",
    "    ],\n",
    "    filled_in_mode=[\n",
    "        'Promo',\n",
    "    ],\n",
    "    target=[\n",
    "        'Sales',\n",
    "    ],\n",
    ")\n",
    "\n",
    "cleaning = DataCleaning(\n",
    "    store=df_store,\n",
    "    hot_encoded_columns=cleaning_settings['hot_encoded_columns'],\n",
    "    dropped_columns=cleaning_settings['dropped_columns'],\n",
    "    filled_in_median=cleaning_settings['filled_in_median'],\n",
    "    filled_in_mode=cleaning_settings['filled_in_mode'],\n",
    "    target=cleaning_settings['target'],\n",
    ")\n",
    "\n",
    "X_train_clean, y_train_clean =\\\n",
    "    cleaning.cleaning(X_train, y_train, training=True)\n",
    "X_val_clean, y_val_clean =\\\n",
    "    cleaning.cleaning(X_val, y_val, training=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "xg_settings = dict(\n",
    "    n_estimators=500,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=CORES,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pipes = define_pipelines(xg_settings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, y_train, X_val, y_val, training_metrics, validation_metrics = \\\n",
    "            single_run(pipes, X_train_clean, y_train_clean,\n",
    "                               X_val_clean, y_val_clean, X_train, X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def merge_data(train, store):\n",
    "        \n",
    "        \"\"\" Takes two dataframes,\n",
    "            creates two copies\n",
    "            drop the customers axis\n",
    "            drop the nan for sale and stores\n",
    "            make sure the store coumns are of the same type. \n",
    "            inner merge on the column store.  \"\"\"\n",
    "        train_copy = train.copy()\n",
    "        store_copy = store.copy()\n",
    "        train_copy = train_copy.drop(columns = ['Customers'])\n",
    "        train_copy = train_copy.dropna(axis = 0, how = 'any', subset = ['Sales', 'Store'])\n",
    "        train_copy['Store'] = train_copy['Store'].astype(int)\n",
    "        store_copy['Store'] = store_copy['Store'].astype(int)\n",
    "        df_p = pd.merge(train_copy, store_copy, how = 'inner', on = 'Store')\n",
    "    \n",
    "        return df_p\n",
    "\n",
    "df_p = merge_data(df_train, df_store)\n",
    "\n",
    "dropped_columns_n = ['CompetitionOpenSinceMonth', 'CompetitionOpenSinceYear',\\\n",
    "                   'Promo2SinceWeek', 'Promo2SinceYear', 'PromoInterval']\n",
    "df_p1 = df_p.drop(columns = dropped_columns_n)\n",
    "\n",
    "# Estimate day-month-year etc\n",
    "\n",
    "df_unclean = df_p1.copy()\n",
    "df_unclean['Date'] = pd.to_datetime(df_unclean['Date'])    \n",
    "df_unclean['day'] = df_unclean['Date'].dt.day\n",
    "df_unclean['month'] = df_unclean['Date'].dt.month\n",
    "df_unclean['year'] = df_unclean['Date'].dt.year\n",
    "df_unclean['weekday_name'] = df_unclean['Date'].dt.day_name()\n",
    "df_unclean['weekday'] = df_unclean['Date'].apply(lambda x: x.weekday())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Getting clean data for plotting purposes: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train = df_train.drop(columns='Sales')\n",
    "y_train = df_train.loc[:, 'Sales']\n",
    "X_val = df_test.drop(columns='Sales')\n",
    "y_val = df_test.loc[:, 'Sales']\n",
    "\n",
    "cleaning_settings = dict(\n",
    "    hot_encoded_columns=[],\n",
    "    dropped_columns=[\n",
    "        'CompetitionOpenSinceMonth',\n",
    "        'CompetitionOpenSinceYear',\n",
    "        'Promo2SinceWeek',\n",
    "        'Promo2SinceYear',\n",
    "        'PromoInterval',\n",
    "    ],\n",
    "    filled_in_median=[\n",
    "        'CompetitionDistance',\n",
    "    ],\n",
    "    filled_in_mode=[\n",
    "        'Promo',\n",
    "    ],\n",
    "    target=[\n",
    "        'Sales',\n",
    "    ],\n",
    ")\n",
    "\n",
    "cleaning = DataCleaning(\n",
    "    store=df_store,\n",
    "    hot_encoded_columns=cleaning_settings['hot_encoded_columns'],\n",
    "    dropped_columns=cleaning_settings['dropped_columns'],\n",
    "    filled_in_median=cleaning_settings['filled_in_median'],\n",
    "    filled_in_mode=cleaning_settings['filled_in_mode'],\n",
    "    target=cleaning_settings['target'],\n",
    ")\n",
    "\n",
    "X_train_clean, y_train_clean =\\\n",
    "    cleaning.cleaning(X_train, y_train, training=True)\n",
    "X_val_clean, y_val_clean =\\\n",
    "    cleaning.cleaning(X_val, y_val, training=False)\n",
    "\n",
    "# Concatenate features and target in validation test \n",
    "df_v = pd.concat([X_val_clean, y_val_clean], axis=1)\n",
    "\n",
    "# Create day, month, year from Datetime\n",
    "df_v1 = df_v.copy()\n",
    "df_v1[\"Date\"] = pd.to_datetime(df_v1['Date'])\n",
    "df_v1['day'] = df_v1['Date'].dt.day\n",
    "df_v1['month'] = df_v1['Date'].dt.month\n",
    "df_v1['year'] = df_v1['Date'].dt.year\n",
    "df_v1['weekday'] = df_v1['Date'].apply(lambda x: x.weekday())\n",
    "\n",
    "#Concatenate train data with predictions\n",
    "iModel = 0 # index in metrics dict . 1 for RandomForestRegressor, 0 for XGBRegressor\n",
    "df_val = pd.concat([df_v1, pd.DataFrame(validation_metrics[iModel][\"prediction\"], columns=[\"Prediction\"],index=df_v1.index)], axis=1)\n",
    "# Add absolute error \n",
    "df_val[\"abserror\"] = np.abs(df_val[\"Prediction\"] - df_val[\"Sales\"])\n",
    "\n",
    "# Add error quartiles rank\n",
    "df_val['ErrorQuaritile'] = pd.qcut(df_val['abserror'], 4, labels=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "\n",
    "dict_stateholiday_rename = {\"a\" : \"publicHoliday\", \n",
    "                             \"b\" : \"Easter\", \n",
    "                             \"c\" : \"Christmas\", \n",
    "                             \"no\" : \"No StateHoliday\"}\n",
    "df_val[\"StateHoliday\"] = df_val[[\"StateHoliday\"]].replace(dict_stateholiday_rename)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Sales Distribution\n",
    "def groupstore(df, storetype:str):\n",
    "    \"\"\" Get dataframe with avgError and CompetitionDistance grouped by Store\"\"\"\n",
    "    df_n = pd.DataFrame(df\\\n",
    "                    .query(f\"StoreType=='{storetype}'\")\\\n",
    "                    .groupby([\"Store\"])[\"Sales\", \"abserror\", \"CompetitionDistance\"]\\\n",
    "                    .mean())\\\n",
    "                    .assign(StoreType=storetype)\n",
    "    return df_n   \n",
    "\n",
    "unique_storetypes = df_val[\"StoreType\"].unique()\n",
    "\n",
    "df_val_grpstore= pd.concat(\n",
    "    [groupstore(df_val, storetype) \\\n",
    "     for storetype in unique_storetypes], axis=0\n",
    ")\n",
    "\n",
    "df_val_grpstore\n",
    "\n",
    "px.histogram(\n",
    "    df_val_grpstore,\n",
    "    x=\"Sales\",\n",
    "    marginal=\"box\",\n",
    "    nbins=40,\n",
    "    width=950,\n",
    "    height=500,\n",
    "    title='Sales Distribution')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "# Sales per Weekday\n",
    "px.box(\n",
    "    df_val,\n",
    "    x=\"weekday\",\n",
    "    y=\"Sales\",\n",
    "    color=\"weekday\",\n",
    "    width=950,\n",
    "    height=600,\n",
    "    title='Sales per Weekday',\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "  # Sales per Weekday\n",
    "px.box(\n",
    "    df_val,\n",
    "    x=\"weekday\",\n",
    "    y=\"Sales\",\n",
    "    color=\"weekday\",\n",
    "    facet_col=\"StoreType\",\n",
    "    width=950,\n",
    "    height=600,\n",
    "    title='Sales per Weekday',\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"], },\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Sales per StoreType per Assortment\n",
    "px.box(\n",
    "    df_val,\n",
    "    x=\"StoreType\",\n",
    "    y=\"Sales\",\n",
    "    color=\"Assortment\",\n",
    "    width=800,\n",
    "    height=500,\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"],\n",
    "                    \"Assortment\": [\"a\", \"b\", \"c\"]},\n",
    "    title=\"Sales per StoreType per Assortment\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Extract & Plot Feature Importances from metrics dict\n",
    "\n",
    "def df_feat_imp_model(iModel, metrics):\n",
    "    \"\"\"Returns DataFrame with 3 features: FeaturesName, Importance and ModelType\"\"\"\n",
    "\n",
    "    feat_importance = metrics[iModel][\"feat_importance\"]\n",
    "    df_feat_imp = pd.DataFrame([feat[0] for feat in feat_importance], columns=[\"Feature\"])\n",
    "    df_feat_imp[\"Importance\"] = [feat[1] for feat in feat_importance]\n",
    "    df_feat_imp.sort_values(\"Importance\", ascending=False, inplace=True)\n",
    "    df_feat_imp[\"Model\"] = validation_metrics[iModel][\"model\"].__name__\n",
    "    \n",
    "    return df_feat_imp\n",
    "\n",
    "df_feat_imp_vstack = pd.concat([df_feat_imp_model(iModel, validation_metrics)\\\n",
    "                               for iModel in range(len(validation_metrics))],\n",
    "                              axis=0)\n",
    "\n",
    "# Once it is in tidy format, plotly express allows you to build complex interactive plots with a one-liner:\n",
    "fig3 = px.bar(\n",
    "    data_frame=df_feat_imp_vstack,\n",
    "    x='Importance',\n",
    "    y='Feature',\n",
    "    width=600,\n",
    "    height=900,\n",
    "    orientation=\"h\",\n",
    "    title= \"Feature Importances\",\n",
    "    #animation_frame=\"Model\", \n",
    "    #animation_group=\"country\"\n",
    "    #category_orders={\"initial\":[\"False\", \"True\"]}\n",
    ")\n",
    "\n",
    "fig3.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "\n",
    "fig3\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Time-series of Sales : Target vs. Prediction\n",
    "df_n = pd.DataFrame(df_val\\\n",
    "                .groupby([\"Date\"])[\"Sales\", \"Prediction\"]\\\n",
    "                .mean())\n",
    "df_n\n",
    "\n",
    "df_targ = df_n[[\"Sales\"]]\n",
    "df_targ[\"Y_type\"] = \"Target\"\n",
    "\n",
    "df_pred = df_n[[\"Prediction\"]]\n",
    "df_pred = df_pred.rename(columns={\"Prediction\" : \"Sales\"})\n",
    "df_pred[\"Y_type\"] = \"Prediction\"\n",
    "\n",
    "df_date = pd.concat([df_targ, df_pred], axis=0)\n",
    "df_date = df_date.reset_index()\n",
    "df_date[\"Date\"] = pd.to_datetime(df_date['Date'])\n",
    "weekday = df_date[\"Date\"].dt.weekday\n",
    "\n",
    "px.scatter(\n",
    "    df_date,\n",
    "    x=\"Date\", \n",
    "    y=\"Sales\",\n",
    "    color=\"Y_type\",\n",
    "    hover_data= [weekday],\n",
    "    width=950,\n",
    "    height=500,\n",
    "    title='Sales over time: Target vs. Prediction')\\\n",
    "    .update_traces(mode='lines+markers')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Time-series of Sales for every Store Type\n",
    "\n",
    "def groupdate_sales_storetype(df, storetype:str):\n",
    "    \"\"\" Get dataframe with avgSales and StoreType grouped by Date \"\"\"\n",
    "    df_n = pd.DataFrame(df\\\n",
    "                    .query(f\"StoreType=='{storetype}'\")\\\n",
    "                    .groupby([\"Date\"])[\"Sales\", \"Prediction\"]\\\n",
    "                    .mean())\\\n",
    "                    .assign(StoreType=storetype)\n",
    "    return df_n   \n",
    "\n",
    "# a. For each StoreType : Get dataframe with avgSales and StoreType grouped by Date\"\"\"\n",
    "# b. Concatenate across rows \n",
    "\n",
    "unique_storetypes = df_val[\"StoreType\"].unique()\n",
    "\n",
    "df_grpday_sort = pd.concat(\n",
    "    [groupdate_sales_storetype(df_val, storetype) \\\n",
    "     for storetype in unique_storetypes], axis=0\n",
    ")\n",
    "\n",
    "\n",
    "df_targ1 = df_grpday_sort[[\"Sales\" , \"StoreType\"]]\n",
    "df_targ1[\"Y_type\"] = \"Target\"\n",
    "\n",
    "df_pred1 = df_grpday_sort[[\"Prediction\" , \"StoreType\"]]\n",
    "df_pred1 = df_pred1.rename(columns={\"Prediction\" : \"Sales\"})\n",
    "df_pred1[\"Y_type\"] = \"Prediction\"\n",
    "\n",
    "df_date1 = pd.concat([df_targ1, df_pred1], axis=0)\n",
    "\n",
    "df_date1 = df_date1.reset_index()\n",
    "df_date1\n",
    "\n",
    "weekday1 = df_date1[\"Date\"].dt.weekday\n",
    "\n",
    "# Time-series of Sales for every Store Type\n",
    "px.scatter(\n",
    "    df_date1,\n",
    "    x=\"Date\", \n",
    "    y=\"Sales\",\n",
    "    color=\"Y_type\",\n",
    "    facet_row=\"StoreType\",\n",
    "    hover_data=[weekday1],\n",
    "    width=950,\n",
    "    height=900,\n",
    "    title='Sales over time: Target vs. Prediction per StoryType')\\\n",
    "    .update_traces(mode='lines+markers')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Error per Weekday\n",
    "px.box(\n",
    "    df_val,\n",
    "    x=\"weekday\",\n",
    "    y=\"abserror\",\n",
    "    color=\"weekday\",\n",
    "    width=950,\n",
    "    height=600,\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"]},\n",
    "    points=False,\n",
    "    title='Error per Weekday')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Error per StoreType\n",
    "px.box(\n",
    "    df_val,\n",
    "    x=\"StoreType\",\n",
    "    y=\"abserror\",\n",
    "    color=\"StoreType\",\n",
    "    width=600,\n",
    "    height=500,\n",
    "    category_orders={\"StoreType\": [\"a\", \"b\", \"c\", \"d\"]},\n",
    "    points=False,\n",
    "    title='Error per StoreType')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 'Error per StateHoliday'\n",
    "px.box(\n",
    "    df_val,\n",
    "    x=\"StateHoliday\",\n",
    "    y=\"abserror\",\n",
    "    color=\"StateHoliday\",\n",
    "    width=750,\n",
    "    height=500,\n",
    "    points=False,\n",
    "    title='Error per StateHoliday')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Relation of Errors with Sales\n",
    "\n",
    "px.scatter(\n",
    "    df_val_grpstore,\n",
    "    x=\"Sales\", \n",
    "    y=\"abserror\",\n",
    "    color=\"StoreType\",\n",
    "    trendline=\"ols\",\n",
    "    marginal_y=\"box\",\n",
    "    marginal_x=\"box\", \n",
    "    width=600,\n",
    "    height=600,\n",
    "    title='Absolute Error ~ Sales')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d19314d9020e914d744f2de230b7e704f3805b9660f27ba32ac517cf1b2bef2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('minicomp-rossman': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}